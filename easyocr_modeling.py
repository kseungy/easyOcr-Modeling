# -*- coding: utf-8 -*-
"""easyOCR 모델링

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tidBwq6ndiLaUPK0zstXr4cctCj2lPIY
"""

# https://davelogs.tistory.com/78?category=928468
# https://cvml.tistory.com/22?category=854254
# https://velog.io/@apphia39/python-CRNN-%ED%95%9C%EA%B8%80-%EB%AA%A8%EB%8D%B8-%ED%95%99%EC%8A%B5%ED%95%98%EA%B8%B0

from google.colab import drive
drive.mount('/content/drive')

# OCR test

pip install git+git://github.com/jaidedai/easyocr.git

import easyocr
reader = easyocr.Reader(['ko','en'])

import PIL
from PIL import ImageDraw
im = PIL.Image.open("/content/drive/MyDrive/image2.PNG")

im

bounds = reader.readtext('/content/drive/MyDrive/image2.PNG')
bounds

# Draw bounding boxes
def draw_boxes(image, bounds, color='yellow', width=2):
    draw = ImageDraw.Draw(image)
    for bound in bounds:
        p0, p1, p2, p3 = bound[0]
        draw.line([*p0, *p1, *p2, *p3, *p0], fill=color, width=width)
    return image

draw_boxes(im, bounds)

# 한글데이터 만들기

!git clone https://github.com/Belval/TextRecognitionDataGenerator.git

!pip3 install -r /content/TextRecognitionDataGenerator/requirements.txt

# !python3 /content/TextRecognitionDataGenerator/trdg/run.py -c 100 -l ko

# training: 10,000개
!python3 /content/TextRecognitionDataGenerator/trdg/run.py \
        --output_dir "/content/step1/training/kordata" \
        --language "ko" \
        --count 10000

# validation: 1,000개
!python3 /content/TextRecognitionDataGenerator/trdg/run.py \
        --output_dir "/content/step1/validation/kordata" \
        --language "ko" \
        --count 1000

# test: 1,000개
!python3 /content/TextRecognitionDataGenerator/trdg/run.py \
        --output_dir "/content/step1/test/kordata" \
        --language "ko" \
        --count 1000

# 한글 데이터 변환하기

!git clone https://github.com/DaveLogs/TRDG2DTRB.git

!python3 /content/TRDG2DTRB/convert.py \
    --input_path ./out \
    --output_path ./output

# train 학습데이터 변환
!python3 /content/TRDG2DTRB/convert.py \
        --input_path "/content/step1/training/kordata" \
        --output_path "/content/step2/training/kordata"

# validation 학습데이터 변환
!python3 /content/TRDG2DTRB/convert.py \
        --input_path "/content/step1/validation/kordata" \
        --output_path "/content/step2/validation/kordata"

# test 학습데이터 변환
!python3 /content/TRDG2DTRB/convert.py \
        --input_path "/content/step1/test/kordata" \
        --output_path "/content/step2/test/kordata"

# 모델 학습

!git clone https://github.com/clovaai/deep-text-recognition-benchmark.git

!pip3 install torch torchvision
!pip3 install lmdb pillow nltk natsort
!pip3 install fire

# 학습데이터를 lmdb 포맷으로 변환하기
#! python3 /content/deep-text-recognition-benchmark/create_lmdb_dataset.py \
#        --inputPath /content/output \
#        --gtFile /content/output/gt.txt \
#        --outputPath result/

# training 데이터 변환
!python3 /content/deep-text-recognition-benchmark/create_lmdb_dataset.py \
        --gtFile "/content/step2/training/kordata/gt.txt" \
        --inputPath "/content/step2/training/kordata" \
        --outputPath "/content/step3/training/kordata"

# validation 데이터 변환
! python3 /content/deep-text-recognition-benchmark/create_lmdb_dataset.py \
        --gtFile "/content/step2/validation/kordata/gt.txt" \
        --inputPath "/content/step2/validation/kordata" \
        --outputPath "/content/step3/validation/kordata"

# test 데이터 변환
! python3 /content/deep-text-recognition-benchmark/create_lmdb_dataset.py \
        --gtFile "/content/step2/test/kordata/gt.txt" \
        --inputPath "/content/step2/test/kordata" \
        --outputPath "/content/step3/test/kordata"



# custom data 학습 /content/pre_trained_model

# Commented out IPython magic to ensure Python compatibility.
# %cd deep-text-recognition-benchmark

# 모델 가져오기
models = {
    'None-ResNet-None-CTC.pth': 'https://drive.google.com/open?id=1FocnxQzFBIjDT2F9BkNUiLdo1cC3eaO0',
    'None-VGG-BiLSTM-CTC.pth': 'https://drive.google.com/open?id=1GGC2IRYEMQviZhqQpbtpeTgHO_IXWetG',
    'None-VGG-None-CTC.pth': 'https://drive.google.com/open?id=1FS3aZevvLiGF1PFBm5SkwvVcgI6hJWL9',
    'TPS-ResNet-BiLSTM-Attn-case-sensitive.pth': 'https://drive.google.com/open?id=1ajONZOgiG9pEYsQ-eBmgkVbMDuHgPCaY',
    'TPS-ResNet-BiLSTM-Attn.pth': 'https://drive.google.com/open?id=1b59rXuGGmKne1AuHnkgDzoYgKeETNMv9',
    'TPS-ResNet-BiLSTM-CTC.pth': 'https://drive.google.com/open?id=1FocnxQzFBIjDT2F9BkNUiLdo1cC3eaO0',
    'korean_g2.pth' : 'https://drive.google.com/file/d/1Ag1UxL_NFaDZslaK3hDzdIn5AhaILEnl/view?usp=sharing'
}

for k, v in models.items():
  doc_id = v[v.find('=')+1:]
  !curl -c /tmp/cookies "https://drive.google.com/uc?export=download&id=$doc_id" > /tmp/intermezzo.html
  !curl -L -b /tmp/cookies "https://drive.google.com$(cat /tmp/intermezzo.html | grep -Po 'uc-download-link" [^>]* href="\K[^"]*' | sed 's/\&amp;/\&/g')" > $k

!ls -al *.pth

# Commented out IPython magic to ensure Python compatibility.
# %cd /content

# deep-text-recognition-benchmark 프로젝트 'train.py'의 285라인에 아래 코드를 삽입한다.
# 아래 character는 EasyOCR 프로젝트 './easyocr/config.py'의 'korean_g2' > 'character'에 해당한다.

! python3 /content/deep-text-recognition-benchmark/train.py \
        --train_data /content/step3/training/kordata \
        --valid_data /content/step3/validation/kordata \
        --data_filtering_off \
        --sensitive \
        --Transformation None \
        --FeatureExtraction VGG \
        --SequenceModeling BiLSTM \
        --Prediction CTC \
        --input_channel 1 \
        --output_channel 256 \
        --hidden_size 256 \
        --saved_model /content/deep-text-recognition-benchmark/korean_g2.pth \
        --FT

# https://cvml.tistory.com/22
# 한글 학습 / /content/deep-text-recognition-benchmark/train.py
# parser.add_argument('--character', type=str,default=
# '0123456789abcdefghijklmnopqrstuvwxyz가각간갇갈감갑값갓강갖같갚갛개객걀걔거걱건걷걸검겁것겉게겨격겪견결겹경곁계고곡곤곧골곰곱곳공과관광괜괴굉교구국군굳굴굵굶굽궁권귀귓규균귤그극근글긁금급긋긍기긴길김깅깊까깍깎깐깔깜깝깡깥깨꺼꺾껌껍껏껑께껴꼬꼭꼴꼼꼽꽂꽃꽉꽤꾸꾼꿀꿈뀌끄끈끊끌끓끔끗끝끼낌나낙낚난날낡남납낫낭낮낯낱낳내냄냇냉냐냥너넉넌널넓넘넣네넥넷녀녁년념녕노녹논놀놈농높놓놔뇌뇨누눈눕뉘뉴늄느늑는늘늙능늦늬니닐님다닥닦단닫달닭닮담답닷당닿대댁댐댓더덕던덜덟덤덥덧덩덮데델도독돈돌돕돗동돼되된두둑둘둠둡둥뒤뒷드득든듣들듬듭듯등디딩딪따딱딴딸땀땅때땜떠떡떤떨떻떼또똑뚜뚫뚱뛰뜨뜩뜯뜰뜻띄라락란람랍랑랗래랜램랫략량러럭런럴럼럽럿렁렇레렉렌려력련렬렵령례로록론롬롭롯료루룩룹룻뤄류륙률륭르른름릇릎리릭린림립릿링마막만많말맑맘맙맛망맞맡맣매맥맨맵맺머먹먼멀멈멋멍멎메멘멩며면멸명몇모목몬몰몸몹못몽묘무묵묶문묻물뭄뭇뭐뭘뭣므미민믿밀밉밌및밑바박밖반받발밝밟밤밥방밭배백뱀뱃뱉버번벌범법벗베벤벨벼벽변별볍병볕보복볶본볼봄봇봉뵈뵙부북분불붉붐붓붕붙뷰브븐블비빌빔빗빚빛빠빡빨빵빼뺏뺨뻐뻔뻗뼈뼉뽑뿌뿐쁘쁨사삭산살삶삼삿상새색샌생샤서석섞선설섬섭섯성세섹센셈셋셔션소속손솔솜솟송솥쇄쇠쇼수숙순숟술숨숫숭숲쉬쉰쉽슈스슨슬슴습슷승시식신싣실싫심십싯싱싶싸싹싼쌀쌍쌓써썩썰썹쎄쏘쏟쑤쓰쓴쓸씀씌씨씩씬씹씻아악안앉않알앓암압앗앙앞애액앨야약얀얄얇양얕얗얘어억언얹얻얼엄업없엇엉엊엌엎에엔엘여역연열엷염엽엿영옆예옛오옥온올옮옳옷옹와완왕왜왠외왼요욕용우욱운울움웃웅워원월웨웬위윗유육율으윽은을음응의이익인일읽잃임입잇있잊잎자작잔잖잘잠잡잣장잦재쟁쟤저적전절젊점접젓정젖제젠젯져조족존졸좀좁종좋좌죄주죽준줄줌줍중쥐즈즉즌즐즘증지직진질짐집짓징짙짚짜짝짧째쨌쩌쩍쩐쩔쩜쪽쫓쭈쭉찌찍찢차착찬찮찰참찻창찾채책챔챙처척천철첩첫청체쳐초촉촌촛총촬최추축춘출춤춥춧충취츠측츰층치칙친칠침칫칭카칸칼캄캐캠커컨컬컴컵컷케켓켜코콘콜콤콩쾌쿄쿠퀴크큰클큼키킬타탁탄탈탑탓탕태택탤터턱턴털텅테텍텔템토톤톨톱통퇴투툴툼퉁튀튜트특튼튿틀틈티틱팀팅파팎판팔팝패팩팬퍼퍽페펜펴편펼평폐포폭폰표푸푹풀품풍퓨프플픔피픽필핏핑하학한할함합항해핵핸햄햇행향허헌험헤헬혀현혈협형혜호혹혼홀홈홉홍화확환활황회획횟횡효후훈훌훔훨휘휴흉흐흑흔흘흙흡흥흩희흰히힘?!', help='character label')
# 249 / parser.add_argument('--select_data', type=str, default='/', help='select training data (default is MJ-ST, which means MJ and ST used as training data)')
# 251 / parser.add_argument('--batch_ratio', type=str, default='1',help='assign ratio for each selected data in the batch')
#  --batch_size에서 default=192의 값을 자신의 그래픽카드 환경에 맞게 수정하기 / 저는 V-Ram이 부족해서 batch_size를 32로 수정했습니다.

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!CUDA_VISIBLE_DEVICES=0 python3 /content/deep-text-recognition-benchmark/train.py\ --train_data /content/step3/training/kordata --valid_data /content/step3/validation/kordata \
	--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction CTC \
	--data_filtering_off --workers 0 --imgH 64 --imgW 200

!CUDA_VISIBLE_DEVICES = 0 python3 demo.py \
        --Transformation None \
        --FeatureExtraction VGG \
        --SequenceModeling BiLSTM \
        --Prediction CTC \
        --image_folder demo_image/ \
        --saved_model ./models/None-VGG-BiLSTM-CTC.pth

!python3 /content/deep-text-recognition-benchmark/demo.py \
        --Transformation None \
        --FeatureExtraction VGG \
        --SequenceModeling BiLSTM \
        --Prediction CTC \
        --image_folder /content/deep-text-recognition-benchmark/demo_image \
        --saved_model /content/deep-text-recognition-benchmark/None-VGG-BiLSTM-CTC.pth

!python3 /content/deep-text-recognition-benchmark/train.py \
    --train_data /content/step3/training/kordata \
    --valid_data /content/step3/validation/kordata \
    --select_data / \
    --batch_ratio 1 \
    --Transformation None \
    --FeatureExtraction VGG \
    --SequenceModeling BiLSTM \
    --Prediction CTC \
    --saved_model /content/deep-text-recognition-benchmark/None-VGG-BiLSTM-CTC.pth \
    --FT

